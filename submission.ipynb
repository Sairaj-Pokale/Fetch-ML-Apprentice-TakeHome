{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74c8ee5",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6860864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saira\\miniforge3\\envs\\fetcch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy, F1Score\n",
    "from torchmetrics import MetricCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c70465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9b1fe",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f449268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fff7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"This is an example sentence\", \n",
    "            \"The sun began to set, casting long shadows across the landscape. A gentle breeze rustled the leaves in the nearby trees, creating a soothing sound. It was the end of another peaceful day.\",\n",
    "            \"Ancient civilizations often looked to the stars for guidance, weaving intricate mythologies around the celestial bodies. These stories, passed down through generations, not only explained the cosmos but also provided moral and social frameworks. Astronomers of antiquity, without the aid of modern technology, made remarkably accurate observations, charting the movements of planets and predicting eclipses with impressive precision. Their understanding of the universe, though different from ours, laid the groundwork for future scientific inquiry and our ongoing quest to comprehend the vastness of space.\",\n",
    "            \"The intricate dance of supply and demand forms the bedrock of most modern economies, a dynamic interplay that dictates the prices of goods and services, influences production levels, and ultimately shapes employment opportunities. When demand for a particular product surges, and supply remains constant or diminishes, prices naturally tend to rise, signaling to producers that there's an unmet need in the market. Conversely, if supply outstrips demand, prices typically fall, prompting businesses to potentially scale back production or find new markets. This self-regulating mechanism, often referred to as the invisible hand, can, in theory, lead to an efficient allocation of resources. However, various factors, including government interventions like subsidies or taxes, monopolistic practices, externalities such as pollution, and unforeseen global events like pandemics or geopolitical conflicts, can significantly distort this delicate balance, leading to market inefficiencies and requiring careful economic management and policy considerations to mitigate negative consequences and promote stability and growth. Understanding these fundamental principles is crucial for individuals, businesses, and policymakers alike as they navigate the complexities of the global marketplace.\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6de5eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639e310",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ee333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTransformer(L.LightningModule):\n",
    "    \"\"\"\n",
    "    How to pool the features to handle the temporal aspect, do we use the pooler output or manually mean pool the features. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        model_output = self.backbone(**x) \n",
    "        # pooled_output = self.mean_pooling(model_output, x['attention_mask']) # mean pool\n",
    "        # pooled_output = F.normalize(pooled_output, p=2, dim=1)\n",
    "        # return pooled_output \n",
    "        \n",
    "        return model_output.pooler_output # raw pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f763dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 384])\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer()\n",
    "outputs = model(encoded_input)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e99e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0134,  0.0400,  0.0031,  ...,  0.0389, -0.0683, -0.0096],\n",
       "        [-0.0300, -0.0377,  0.0264,  ...,  0.0243, -0.0514,  0.0253],\n",
       "        [-0.0254,  0.0243,  0.0588,  ..., -0.0123, -0.0427, -0.0049],\n",
       "        [-0.0319, -0.0019,  0.0244,  ...,  0.0093, -0.0662,  0.0180]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', SentenceTransformer(\n",
      "  (backbone): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 384)\n",
      "      (token_type_embeddings): Embedding(2, 384)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "))\n",
      "('backbone', BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 384)\n",
      "    (token_type_embeddings): Embedding(2, 384)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "))\n",
      "('backbone.embeddings', BertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 384)\n",
      "  (token_type_embeddings): Embedding(2, 384)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.embeddings.word_embeddings', Embedding(30522, 384, padding_idx=0))\n",
      "('backbone.embeddings.position_embeddings', Embedding(512, 384))\n",
      "('backbone.embeddings.token_type_embeddings', Embedding(2, 384))\n",
      "('backbone.embeddings.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.embeddings.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder', BertEncoder(\n",
      "  (layer): ModuleList(\n",
      "    (0-5): 6 x BertLayer(\n",
      "      (attention): BertAttention(\n",
      "        (self): BertSdpaSelfAttention(\n",
      "          (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (output): BertSelfOutput(\n",
      "          (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (intermediate): BertIntermediate(\n",
      "        (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (intermediate_act_fn): GELUActivation()\n",
      "      )\n",
      "      (output): BertOutput(\n",
      "        (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer', ModuleList(\n",
      "  (0-5): 6 x BertLayer(\n",
      "    (attention): BertAttention(\n",
      "      (self): BertSdpaSelfAttention(\n",
      "        (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (output): BertSelfOutput(\n",
      "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (intermediate): BertIntermediate(\n",
      "      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "    )\n",
      "    (output): BertOutput(\n",
      "      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.0', BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.0.attention', BertAttention(\n",
      "  (self): BertSdpaSelfAttention(\n",
      "    (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output): BertSelfOutput(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.0.attention.self', BertSdpaSelfAttention(\n",
      "  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.0.attention.self.query', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.0.attention.self.key', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.0.attention.self.value', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.0.attention.self.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.0.attention.output', BertSelfOutput(\n",
      "  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.0.attention.output.dense', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.0.attention.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.0.attention.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.0.intermediate', BertIntermediate(\n",
      "  (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "))\n",
      "('backbone.encoder.layer.0.intermediate.dense', Linear(in_features=384, out_features=1536, bias=True))\n",
      "('backbone.encoder.layer.0.intermediate.intermediate_act_fn', GELUActivation())\n",
      "('backbone.encoder.layer.0.output', BertOutput(\n",
      "  (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.0.output.dense', Linear(in_features=1536, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.0.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.0.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.1', BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.1.attention', BertAttention(\n",
      "  (self): BertSdpaSelfAttention(\n",
      "    (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output): BertSelfOutput(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.1.attention.self', BertSdpaSelfAttention(\n",
      "  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.1.attention.self.query', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.1.attention.self.key', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.1.attention.self.value', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.1.attention.self.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.1.attention.output', BertSelfOutput(\n",
      "  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.1.attention.output.dense', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.1.attention.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.1.attention.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.1.intermediate', BertIntermediate(\n",
      "  (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "))\n",
      "('backbone.encoder.layer.1.intermediate.dense', Linear(in_features=384, out_features=1536, bias=True))\n",
      "('backbone.encoder.layer.1.intermediate.intermediate_act_fn', GELUActivation())\n",
      "('backbone.encoder.layer.1.output', BertOutput(\n",
      "  (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.1.output.dense', Linear(in_features=1536, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.1.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.1.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.2', BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.2.attention', BertAttention(\n",
      "  (self): BertSdpaSelfAttention(\n",
      "    (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output): BertSelfOutput(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.2.attention.self', BertSdpaSelfAttention(\n",
      "  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.2.attention.self.query', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.2.attention.self.key', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.2.attention.self.value', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.2.attention.self.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.2.attention.output', BertSelfOutput(\n",
      "  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.2.attention.output.dense', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.2.attention.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.2.attention.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.2.intermediate', BertIntermediate(\n",
      "  (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "))\n",
      "('backbone.encoder.layer.2.intermediate.dense', Linear(in_features=384, out_features=1536, bias=True))\n",
      "('backbone.encoder.layer.2.intermediate.intermediate_act_fn', GELUActivation())\n",
      "('backbone.encoder.layer.2.output', BertOutput(\n",
      "  (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.2.output.dense', Linear(in_features=1536, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.2.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.2.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.3', BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.3.attention', BertAttention(\n",
      "  (self): BertSdpaSelfAttention(\n",
      "    (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output): BertSelfOutput(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.3.attention.self', BertSdpaSelfAttention(\n",
      "  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.3.attention.self.query', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.3.attention.self.key', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.3.attention.self.value', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.3.attention.self.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.3.attention.output', BertSelfOutput(\n",
      "  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.3.attention.output.dense', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.3.attention.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.3.attention.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.3.intermediate', BertIntermediate(\n",
      "  (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "))\n",
      "('backbone.encoder.layer.3.intermediate.dense', Linear(in_features=384, out_features=1536, bias=True))\n",
      "('backbone.encoder.layer.3.intermediate.intermediate_act_fn', GELUActivation())\n",
      "('backbone.encoder.layer.3.output', BertOutput(\n",
      "  (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.3.output.dense', Linear(in_features=1536, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.3.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.3.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.4', BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.4.attention', BertAttention(\n",
      "  (self): BertSdpaSelfAttention(\n",
      "    (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output): BertSelfOutput(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.4.attention.self', BertSdpaSelfAttention(\n",
      "  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.4.attention.self.query', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.4.attention.self.key', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.4.attention.self.value', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.4.attention.self.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.4.attention.output', BertSelfOutput(\n",
      "  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.4.attention.output.dense', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.4.attention.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.4.attention.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.4.intermediate', BertIntermediate(\n",
      "  (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "))\n",
      "('backbone.encoder.layer.4.intermediate.dense', Linear(in_features=384, out_features=1536, bias=True))\n",
      "('backbone.encoder.layer.4.intermediate.intermediate_act_fn', GELUActivation())\n",
      "('backbone.encoder.layer.4.output', BertOutput(\n",
      "  (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.4.output.dense', Linear(in_features=1536, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.4.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.4.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.5', BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.5.attention', BertAttention(\n",
      "  (self): BertSdpaSelfAttention(\n",
      "    (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output): BertSelfOutput(\n",
      "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('backbone.encoder.layer.5.attention.self', BertSdpaSelfAttention(\n",
      "  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.5.attention.self.query', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.5.attention.self.key', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.5.attention.self.value', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.5.attention.self.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.5.attention.output', BertSelfOutput(\n",
      "  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.5.attention.output.dense', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.5.attention.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.5.attention.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.encoder.layer.5.intermediate', BertIntermediate(\n",
      "  (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "))\n",
      "('backbone.encoder.layer.5.intermediate.dense', Linear(in_features=384, out_features=1536, bias=True))\n",
      "('backbone.encoder.layer.5.intermediate.intermediate_act_fn', GELUActivation())\n",
      "('backbone.encoder.layer.5.output', BertOutput(\n",
      "  (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "  (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('backbone.encoder.layer.5.output.dense', Linear(in_features=1536, out_features=384, bias=True))\n",
      "('backbone.encoder.layer.5.output.LayerNorm', LayerNorm((384,), eps=1e-12, elementwise_affine=True))\n",
      "('backbone.encoder.layer.5.output.dropout', Dropout(p=0.1, inplace=False))\n",
      "('backbone.pooler', BertPooler(\n",
      "  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "  (activation): Tanh()\n",
      "))\n",
      "('backbone.pooler.dense', Linear(in_features=384, out_features=384, bias=True))\n",
      "('backbone.pooler.activation', Tanh())\n"
     ]
    }
   ],
   "source": [
    "for layername in model.named_modules():\n",
    "    print(layername)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ad754",
   "metadata": {},
   "source": [
    "### Visualizing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_np = outputs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8b8b6",
   "metadata": {},
   "source": [
    "#### Initialize a dimensionality reduction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0960aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_value = min(30.0, float(embeddings_np.shape[0] - 1))\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_value, n_iter=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a7a925",
   "metadata": {},
   "source": [
    "#### Fit embeddings & Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34214c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saira\\miniforge3\\envs\\fetcch\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings_2d = tsne.fit_transform(embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c1c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "sns.scatterplot(x=embeddings_2d[:, 0], y=embeddings_2d[:, 1])\n",
    "plt.title('Sentence Embeddings visualized with t-SNE')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b4fdc",
   "metadata": {},
   "source": [
    "### MultiTask Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a812f",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6485aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskSentenceTransformer(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    MultiTask Learning \n",
    "    Task A: Sentiment Analysis -> Classify sentences/reviews into predefined sentiment classes such as Happy, Sad, & Neutral \n",
    "    Task B: Named Entity Recognition -> Classify words of the sentences into prefined entity classes such as Person, Organization, Location etc.\n",
    "    TODO: Describe the changes made to the architecture to support multi-task learning\n",
    "    -- Added individual task specific heads to the model\n",
    "    -- Updated forward to guide the logits obtained from the backbone to the respective task heads \n",
    "    -- Tried out PyTorch Lightning, a pytorch wrapper, so added the training_step to declare a single training step, same for validation and test  \n",
    "    -- To accomodate the flow of the framework, the loss function and optimizer is declared in the architecture it self\n",
    "    -- Added task specific metrics, Accuracy for sentiment analysis and F1 Score for named entity recognition\n",
    "    \"\"\"\n",
    "    def __init__(self, sentiment_classes, ner_classes, dropout_rate, embedding_dim, ner_ignore_idx):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.sentiment_analysis_head = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(embedding_dim, embedding_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim//2, sentiment_classes)\n",
    "        )\n",
    "        self.named_entity_rec_head = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate), \n",
    "            nn.Linear(embedding_dim, embedding_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim//2, ner_classes)\n",
    "        )\n",
    "        self.sent_crit = nn.CrossEntropyLoss()\n",
    "        self.ner_crit = nn.CrossEntropyLoss(ignore_index=ner_ignore_idx)\n",
    "        self.ner_classes = ner_classes\n",
    "        self.sentiment_acc = Accuracy(task=\"multiclass\", num_classes=sentiment_classes)\n",
    "        self.ner_f1 = F1Score(task=\"multiclass\", num_classes=ner_classes, average='macro', ignore_index=ner_ignore_idx)\n",
    "        \n",
    "    \n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def forward(self, x, task, pooler_type=None):\n",
    "        model_output = self.backbone(**x) \n",
    "        if task=='SEN':\n",
    "            if pooler_type=='native':\n",
    "                pooled_output=model_output.pooler_output\n",
    "            elif pooler_type=='mean':\n",
    "                pooled_output = self.mean_pooling(model_output, x['attention_mask'])\n",
    "                pooled_output = F.normalize(pooled_output, p=2, dim=1)\n",
    "            outputs = self.sentiment_analysis_head(pooled_output)\n",
    "        if task=='NER':\n",
    "            outputs = self.named_entity_rec_head(model_output.last_hidden_state)\n",
    "        return outputs\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        trainable_params = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        optimizer = optim.Adam(trainable_params, lr=3e-5)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        item = batch\n",
    "        task = item.pop('task')[0]\n",
    "        labels = item.pop('labels')\n",
    "        pooler_type = 'mean'\n",
    "        outputs = self(item, task, pooler_type)\n",
    "        print(task)\n",
    "        if task=='SEN':\n",
    "            loss = self.sent_crit(outputs, labels)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = self.sentiment_acc(preds, labels)\n",
    "            self.log(\"train/sentiment_acc\", acc, on_step=False, on_epoch=True)\n",
    "        if task=='NER':\n",
    "            loss = self.ner_crit(outputs.view(-1, self.ner_classes), labels.view(-1))\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            f1 = self.ner_f1(preds.view(-1), labels.view(-1))\n",
    "            self.log(\"train/ner_f1\", f1, on_step=False, on_epoch=True)\n",
    "  \n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pooler_type = 'mean'\n",
    "        item = batch\n",
    "        task = item.pop('task')[0]\n",
    "        labels = item.pop('labels')\n",
    "        outputs = self(item, task, pooler_type)\n",
    "        if task=='SEN':\n",
    "            loss = self.sent_crit(outputs, labels)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = self.sentiment_acc(preds, labels)\n",
    "            self.log(\"val/sentiment_acc\", acc, on_step=False, on_epoch=True)\n",
    "        if task=='NER':\n",
    "            loss = self.ner_crit(outputs.view(-1, self.ner_classes), labels.view(-1))\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            f1 = self.ner_f1(preds.view(-1), labels.view(-1))\n",
    "            self.log(\"val/ner_f1\", f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        pooler_type = 'mean'\n",
    "        item = batch\n",
    "        task = item.pop('task')[0]\n",
    "        labels = item.pop('labels')\n",
    "        outputs = self(item, task, pooler_type)\n",
    "        if task=='SEN':\n",
    "            loss = self.sent_crit(outputs, labels)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = self.sentiment_acc(preds, labels)\n",
    "            self.log(\"test/sentiment_acc\", acc, on_step=False, on_epoch=True)\n",
    "        if task=='NER':\n",
    "            loss = self.ner_crit(outputs.view(-1, self.ner_classes), labels.view(-1))\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            f1 = self.ner_f1(preds.view(-1), labels.view(-1))\n",
    "            self.log(\"test/ner_f1\", f1, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af9e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = MultiTaskSentenceTransformer(sentiment_classes=3, ner_classes=9, dropout_rate=0.1, embedding_dim=384, ner_ignore_idx=-100)\n",
    "# outputs = model(encoded_input)\n",
    "# print(outputs.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c602f585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskSentenceTransformer(\n",
       "  (backbone): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (sentiment_analysis_head): Sequential(\n",
       "    (0): Dropout(p=0.1, inplace=False)\n",
       "    (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=192, out_features=3, bias=True)\n",
       "  )\n",
       "  (named_entity_rec_head): Sequential(\n",
       "    (0): Dropout(p=0.1, inplace=False)\n",
       "    (1): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=192, out_features=9, bias=True)\n",
       "  )\n",
       "  (sent_crit): CrossEntropyLoss()\n",
       "  (ner_crit): CrossEntropyLoss()\n",
       "  (sentiment_acc): MulticlassAccuracy()\n",
       "  (ner_f1): MulticlassF1Score()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe60b057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable Parameters\n",
      "sentiment_analysis_head.1.weight\n",
      "sentiment_analysis_head.1.bias\n",
      "sentiment_analysis_head.3.weight\n",
      "sentiment_analysis_head.3.bias\n",
      "named_entity_rec_head.1.weight\n",
      "named_entity_rec_head.1.bias\n",
      "named_entity_rec_head.3.weight\n",
      "named_entity_rec_head.3.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrainable Parameters\")\n",
    "for name, param in multi_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377891f5",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6de42",
   "metadata": {},
   "source": [
    "##### Sentiment Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525ab045",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = [\"This movie was absolutely fantastic! The acting was superb and the storyline was gripping.\", \n",
    "                  \"I'm quite disappointed with the product quality; it broke after just one day of use.\", \n",
    "                  \"The weather today is partly cloudy with a chance of showers later in the afternoon.\", \n",
    "                  \"Customer service was incredibly helpful and resolved my issue in no time!\",\n",
    "                  \"The new software update seems a bit clunky and not very intuitive to navigate.\"]\n",
    "sentiment_labels = [\"Positive\", \"Negative\", \"Neutral\", \"Positive\", \"Negative\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391883c9",
   "metadata": {},
   "source": [
    "##### Named Entity Recognition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a21fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data = [\n",
    "    {\n",
    "        \"sentence\": \"Anna Wintour works for Vogue in New York City.\",\n",
    "        \"tokens_tags\": [\n",
    "            (\"Anna\", \"B-PER\"),\n",
    "            (\"Wintour\", \"I-PER\"),\n",
    "            (\"works\", \"O\"),\n",
    "            (\"for\", \"O\"),\n",
    "            (\"Vogue\", \"B-ORG\"),\n",
    "            (\"in\", \"O\"),\n",
    "            (\"New\", \"B-LOC\"),\n",
    "            (\"York\", \"I-LOC\"),\n",
    "            (\"City\", \"I-LOC\"),\n",
    "            (\".\", \"O\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"The G7 summit will be held in London next June.\",\n",
    "        \"tokens_tags\": [\n",
    "            (\"The\", \"O\"),\n",
    "            (\"G7\", \"B-ORG\"), \n",
    "            (\"summit\", \"O\"),\n",
    "            (\"will\", \"O\"),\n",
    "            (\"be\", \"O\"),\n",
    "            (\"held\", \"O\"),\n",
    "            (\"in\", \"O\"),\n",
    "            (\"London\", \"B-LOC\"),\n",
    "            (\"next\", \"B-MISC\"), \n",
    "            (\"June\", \"I-MISC\"), \n",
    "            (\".\", \"O\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Elon Musk announced that SpaceX will launch Starship next month.\",\n",
    "        \"tokens_tags\": [\n",
    "            (\"Elon\", \"B-PER\"),\n",
    "            (\"Musk\", \"I-PER\"),\n",
    "            (\"announced\", \"O\"),\n",
    "            (\"that\", \"O\"),\n",
    "            (\"SpaceX\", \"B-ORG\"),\n",
    "            (\"will\", \"O\"),\n",
    "            (\"launch\", \"O\"),\n",
    "            (\"Starship\", \"B-MISC\"), \n",
    "            (\"next\", \"O\"),\n",
    "            (\"month\", \"O\"),\n",
    "            (\".\", \"O\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"The FIFA World Cup is a global football tournament organized by FIFA.\",\n",
    "        \"tokens_tags\": [\n",
    "            (\"The\", \"O\"),\n",
    "            (\"FIFA\", \"B-ORG\"), \n",
    "            (\"World\", \"I-MISC\"), \n",
    "            (\"Cup\", \"I-MISC\"),   \n",
    "            (\"is\", \"O\"),\n",
    "            (\"a\", \"O\"),\n",
    "            (\"global\", \"O\"),\n",
    "            (\"football\", \"O\"),\n",
    "            (\"tournament\", \"O\"),\n",
    "            (\"organized\", \"O\"),\n",
    "            (\"by\", \"O\"),\n",
    "            (\"FIFA\", \"B-ORG\"),\n",
    "            (\".\", \"O\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Barack Obama visited Berlin during his presidency.\",\n",
    "        \"tokens_tags\": [\n",
    "            (\"Barack\", \"B-PER\"),\n",
    "            (\"Obama\", \"I-PER\"),\n",
    "            (\"visited\", \"O\"),\n",
    "            (\"Berlin\", \"B-LOC\"),\n",
    "            (\"during\", \"O\"),\n",
    "            (\"his\", \"O\"),\n",
    "            (\"presidency\", \"O\"),\n",
    "            (\".\", \"O\")\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ca605",
   "metadata": {},
   "source": [
    "##### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dac66567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDatasetClass(Dataset):\n",
    "    def __init__(self, sentiment_data, sentiment_labels):\n",
    "        self.texts = sentiment_data\n",
    "        self.labels = sentiment_labels\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.max_length = 128\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encodings = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['task'] = \"SEN\"\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0baa2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_label_id = {\"Positive\":0, \"Negative\":1, \"Neutral\":2}\n",
    "sent_labels = [sent_label_id[lbl] for lbl in sentiment_labels]\n",
    "testdata = SentimentDatasetClass(sentiment_data=sentiment_data, sentiment_labels=sent_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "701ad45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdl = DataLoader(testdata, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9be3313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1996,  4633,  2651,  2003,  6576, 24706,  2007,  1037,  3382,\n",
      "          1997, 23442,  2101,  1999,  1996,  5027,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  1049,  3243,  9364,  2007,  1996,  4031,  3737,\n",
      "          1025,  2009,  3631,  2044,  2074,  2028,  2154,  1997,  2224,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([2, 1]), 'task': ['SEN', 'SEN']}\n",
      "{'input_ids': tensor([[  101,  1996,  4633,  2651,  2003,  6576, 24706,  2007,  1037,  3382,\n",
      "          1997, 23442,  2101,  1999,  1996,  5027,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  1049,  3243,  9364,  2007,  1996,  4031,  3737,\n",
      "          1025,  2009,  3631,  2044,  2074,  2028,  2154,  1997,  2224,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])} SEN\n"
     ]
    }
   ],
   "source": [
    "for batch in testdl:\n",
    "    print(batch)\n",
    "    task = batch.pop('task')[0]\n",
    "    labels = batch.pop('labels')\n",
    "    print(batch, task)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1410f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 1045, 1005, 1049, 3243, 9364, 2007, 1996, 4031, 3737, 1025, 2009,\n",
       "         3631, 2044, 2074, 2028, 2154, 1997, 2224, 1012,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1),\n",
       " 'task': 'SEN'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e0707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDatasetClass(Dataset):\n",
    "    def __init__(self, ner_data, ner_ignore_idx):\n",
    "        self.ner_label_to_id = {\n",
    "                    \"O\":0,\n",
    "                    \"B-PER\": 1,\n",
    "                    \"I-PER\": 2,\n",
    "                    \"B-LOC\": 3,\n",
    "                    \"I-LOC\": 4,\n",
    "                    \"B-ORG\": 5,\n",
    "                    \"I-ORG\": 6,\n",
    "                    \"B-MISC\": 7,\n",
    "                    \"I-MISC\": 8\n",
    "                }\n",
    "        self.id_to_ner_label = {v: k for k, v in self.ner_label_to_id.items()}\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.ner_ignore_idx = ner_ignore_idx\n",
    "        self.data = []\n",
    "        for item in ner_data:\n",
    "            tokens, tags = zip(*item[\"tokens_tags\"])\n",
    "            tag_ids = [self.ner_label_to_id[tag] for tag in tags]\n",
    "            self.data.append({\n",
    "                \"tokens\": list(tokens),\n",
    "                \"labels\": tag_ids,\n",
    "                \"task\": \"NER\"\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        words = item[\"tokens\"]\n",
    "        labels = item[\"labels\"]\n",
    "        encoded = self.tokenizer(words, is_split_into_words=True, return_tensors='pt',\n",
    "                                     padding='max_length', max_length=128, truncation=True)\n",
    "        word_ids = encoded.word_ids(0)\n",
    "        aligned_labels = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned_labels.append(self.ner_ignore_idx)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                aligned_labels.append(labels[word_idx])\n",
    "            else:\n",
    "                aligned_labels.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        item[\"labels\"] = torch.tensor(aligned_labels)\n",
    "        item['task'] = \"NER\"\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945f8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "nertest = NERDatasetClass(ner_data=ner_data, ner_ignore_idx=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db4c90f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 1996, 1043, 2581, 6465, 2097, 2022, 2218, 1999, 2414, 2279, 2238,\n",
       "         1012,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([-100,    0,    5,    5,    0,    0,    0,    0,    0,    3,    7,    8,\n",
       "            0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       " 'task': 'NER'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertest.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817c3b0",
   "metadata": {},
   "source": [
    "##### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba70cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57192a3",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: How the model should be trained given the following:\n",
    "1. If the entire network should be frozen.\n",
    "-- In this case, there would be no layers to train, no parameters would be updated, and the network would \n",
    "    act as a feature extractor, and the logits would be passed to a classifier head to obtain the output,\n",
    "    its not too beneficial as the model would not learn from the mistakes its making.\n",
    "2. If only the transformer backbone should be frozen.\n",
    "-- In this case, with the backbone only frozen, the fixed representations allow us the freedom to tune the \n",
    "    task specific layers, while preserving the knowledge from backbone, this way the task heads effectively \n",
    "    learn the task specific information.  \n",
    "3. If only one of the task-specific heads (either for Task A or Task B) should be frozen.\n",
    "-- This is ideal when let's say the the frozen model performance on Task A is good while it suffers on Task B\n",
    "    so by freezing the layers of Task A head, we can preserve the performance on Task A, while allowing the \n",
    "    the model to be better at Task B.\n",
    "\n",
    "TODO: Explain how you would approach the transfer learning process, including:\n",
    "1. The choice of a pre-trained model.\n",
    "-- Choosing a pre-trained model that is closer to the task at hand is beneficial, as we can use the learned \n",
    "    knowledge for features closer to the task, better features equal better performance.\n",
    "2. The layers you would freeze/unfreeze.\n",
    "-- Freeze the early layers, unfreeze the later layers, the ones closer to task specific heads.\n",
    "3. The rationale behind these choices.\n",
    "-- The earlier layers in a transformer model tend to learn the general information better, \n",
    "    as compared to the later layers, which learn the task specific information. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "trainer_config = {\n",
    "        \"max_epochs\": 20, \n",
    "        \"precision\": \"16-mixed\" if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 32,\n",
    "        \"logger\": pl.loggers.TensorBoardLogger(\"training_logs/\", name=\"mtl_sentiment_ner\"),\n",
    "        \"callbacks\": [\n",
    "            pl.callbacks.ModelCheckpoint(monitor=\"val/loss\", mode=\"min\", save_top_k=1),\n",
    "            pl.callbacks.EarlyStopping(monitor=\"val/loss\", mode=\"min\", patience=3)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    trainer_config[\"accelerator\"] = \"gpu\"\n",
    "    trainer_config[\"devices\"] = 1 \n",
    "    print(f\"Training on GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    trainer_config[\"accelerator\"] = \"cpu\"\n",
    "    print(\"Training on CPU\")\n",
    "\n",
    "trainer = pl.Trainer(**trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c98c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "class SentimentDataModule(LightningDataModule):\n",
    "    def __init__(self, sentiment_data, sentiment_labels, batch_size):\n",
    "        super().__init__()\n",
    "        self.train_texts = sentiment_data\n",
    "        self.train_labels = sentiment_labels\n",
    "        self.val_texts = sentiment_data\n",
    "        self.val_labels = sentiment_labels\n",
    "        self.test_texts = sentiment_data\n",
    "        self.test_labels = sentiment_labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SentimentDatasetClass(self.train_texts, self.train_labels)\n",
    "        self.val_dataset = SentimentDatasetClass(self.val_texts, self.val_labels)\n",
    "        self.test_dataset = SentimentDatasetClass(self.test_texts, self.test_labels)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b64bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Explain any assumptions or decisions made paying special attention to how training within a MTL framework operates.\n",
    "--  The training procedure operates with the assumption, each tasks are trained independently and not together,\n",
    "    to handle this condition, we have defined the forward function of the model to drive the backbone outputs in the \n",
    "    respective task-specific heads. We also need to use the appropriate loss function for each of the tasks, it is especially \n",
    "    cruicial, this is handled in the training step where we use the approprite loss function.\n",
    "    I tried building a combined Dataset class and loader, but that was unseuccessful as the dataloader could not stack \n",
    "    the labels of different shape(1 for sentiment analysis, 128 for NER).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a8b651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dm = SentimentDataModule(sentiment_data=sentiment_data, sentiment_labels=sent_labels, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type               | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | backbone                | BertModel          | 22.7 M | eval \n",
      "1 | sentiment_analysis_head | Sequential         | 74.5 K | train\n",
      "2 | named_entity_rec_head   | Sequential         | 75.7 K | train\n",
      "3 | sent_crit               | CrossEntropyLoss   | 0      | train\n",
      "4 | ner_crit                | CrossEntropyLoss   | 0      | train\n",
      "5 | sentiment_acc           | MulticlassAccuracy | 0      | train\n",
      "6 | ner_f1                  | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "22.7 M    Non-trainable params\n",
      "22.9 M    Total params\n",
      "91.453    Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "120       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]IN MODEL DEF SEN\n",
      "tensor([[-0.0787,  0.0109,  0.0268],\n",
      "        [-0.0703,  0.0027,  0.0213]], device='cuda:0', dtype=torch.float16)\n",
      "Sanity Checking DataLoader 0:  50%|     | 1/2 [00:00<00:00, 44.10it/s]IN MODEL DEF SEN\n",
      "tensor([[-0.0800, -0.0123,  0.0278],\n",
      "        [-0.0697, -0.0055,  0.0208]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s]                             IN MODEL DEF SEN\n",
      "tensor([[-0.0813, -0.0094,  0.0325],\n",
      "        [-0.0735,  0.0096,  0.0238]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 0:  33%|      | 1/3 [00:00<00:00, 37.89it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0666, -0.0103,  0.0192],\n",
      "        [-0.0454,  0.0057,  0.0286]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 0:  67%|   | 2/3 [00:00<00:00, 40.76it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0604,  0.0079,  0.0179]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 0: 100%|| 3/3 [00:00<00:00, 42.99it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0771,  0.0099,  0.0262],\n",
      "        [-0.0698,  0.0024,  0.0212]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0806, -0.0134,  0.0294],\n",
      "        [-0.0689, -0.0059,  0.0205]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0496,  0.0056,  0.0306]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0452,  0.0019,  0.0320],\n",
      "        [-0.0820,  0.0046,  0.0258]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 1:  33%|      | 1/3 [00:00<00:00, 55.04it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0693, -0.0017,  0.0175],\n",
      "        [-0.0660, -0.0103,  0.0209]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 1:  67%|   | 2/3 [00:00<00:00, 57.28it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0809, -0.0122,  0.0283]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 1: 100%|| 3/3 [00:00<00:00, 57.10it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0752,  0.0090,  0.0252],\n",
      "        [-0.0694,  0.0029,  0.0202]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0809, -0.0142,  0.0304],\n",
      "        [-0.0674, -0.0061,  0.0193]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0500,  0.0071,  0.0294]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0784, -0.0133,  0.0284],\n",
      "        [-0.0735,  0.0075,  0.0236]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 2:  33%|      | 1/3 [00:00<00:00, 73.92it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0743,  0.0137,  0.0213],\n",
      "        [-0.0712, -0.0042,  0.0162]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 2:  67%|   | 2/3 [00:00<00:00, 66.36it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0599,  0.0092,  0.0359]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 2: 100%|| 3/3 [00:00<00:00, 69.57it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0739,  0.0085,  0.0245],\n",
      "        [-0.0695,  0.0039,  0.0192]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0817, -0.0151,  0.0320],\n",
      "        [-0.0662, -0.0063,  0.0184]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0504,  0.0082,  0.0287]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0542,  0.0035,  0.0162],\n",
      "        [-0.0834, -0.0169,  0.0296]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 3:  33%|      | 1/3 [00:00<00:00, 66.65it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0710,  0.0037,  0.0249],\n",
      "        [-0.0487,  0.0082,  0.0296]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 3:  67%|   | 2/3 [00:00<00:00, 62.50it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0782,  0.0055,  0.0270]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 3: 100%|| 3/3 [00:00<00:00, 67.80it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0728,  0.0079,  0.0238],\n",
      "        [-0.0696,  0.0048,  0.0182]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0824, -0.0159,  0.0333],\n",
      "        [-0.0651, -0.0063,  0.0175]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0510,  0.0096,  0.0278]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0556,  0.0065,  0.0267],\n",
      "        [-0.0750, -0.0119,  0.0281]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 4:  33%|      | 1/3 [00:00<00:00, 76.29it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0650,  0.0069,  0.0191],\n",
      "        [-0.0715,  0.0072,  0.0244]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 4:  67%|   | 2/3 [00:00<00:00, 74.93it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0654, -0.0023,  0.0173]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 4: 100%|| 3/3 [00:00<00:00, 77.00it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0713,  0.0073,  0.0230],\n",
      "        [-0.0697,  0.0058,  0.0171]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0830, -0.0166,  0.0344],\n",
      "        [-0.0640, -0.0062,  0.0166]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0515,  0.0110,  0.0269]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0587, -0.0028,  0.0173],\n",
      "        [-0.0521,  0.0097,  0.0312]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 5:  33%|      | 1/3 [00:00<00:00, 68.36it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0839, -0.0148,  0.0370],\n",
      "        [-0.0662,  0.0081,  0.0176]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 5:  67%|   | 2/3 [00:00<00:00, 70.98it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0637,  0.0053,  0.0253]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 5: 100%|| 3/3 [00:00<00:00, 70.48it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0699,  0.0068,  0.0222],\n",
      "        [-0.0696,  0.0067,  0.0160]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0835, -0.0173,  0.0353],\n",
      "        [-0.0627, -0.0063,  0.0155]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0518,  0.0123,  0.0260]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0670,  0.0052,  0.0155],\n",
      "        [-0.0889, -0.0210,  0.0426]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 6:  33%|      | 1/3 [00:00<00:00, 49.16it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0655,  0.0160,  0.0159],\n",
      "        [-0.0637, -0.0089,  0.0193]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 6:  67%|   | 2/3 [00:00<00:00, 51.29it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0498,  0.0161,  0.0191]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 6: 100%|| 3/3 [00:00<00:00, 52.98it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0684,  0.0062,  0.0213],\n",
      "        [-0.0697,  0.0079,  0.0148]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0840, -0.0179,  0.0364],\n",
      "        [-0.0616, -0.0064,  0.0145]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0521,  0.0134,  0.0252]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0651,  0.0133,  0.0192],\n",
      "        [-0.0666,  0.0057,  0.0110]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 7:  33%|      | 1/3 [00:00<00:00, 55.34it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0847, -0.0177,  0.0370],\n",
      "        [-0.0507,  0.0187,  0.0241]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 7:  67%|   | 2/3 [00:00<00:00, 50.22it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0632, -0.0017,  0.0120]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 7: 100%|| 3/3 [00:00<00:00, 51.65it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0668,  0.0055,  0.0204],\n",
      "        [-0.0698,  0.0089,  0.0136]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0845, -0.0183,  0.0372],\n",
      "        [-0.0605, -0.0063,  0.0135]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0524,  0.0147,  0.0243]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0492,  0.0209,  0.0236],\n",
      "        [-0.0641, -0.0062,  0.0061]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 8:  33%|      | 1/3 [00:00<00:00, 54.24it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0871, -0.0221,  0.0349],\n",
      "        [-0.0708,  0.0179,  0.0155]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 8:  67%|   | 2/3 [00:00<00:00, 56.67it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0616,  0.0028,  0.0197]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 8: 100%|| 3/3 [00:00<00:00, 56.00it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0655,  0.0050,  0.0195],\n",
      "        [-0.0698,  0.0099,  0.0124]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0850, -0.0189,  0.0381],\n",
      "        [-0.0591, -0.0064,  0.0123]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0527,  0.0159,  0.0233]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0735,  0.0066,  0.0123],\n",
      "        [-0.0539,  0.0173,  0.0276]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 9:  33%|      | 1/3 [00:00<00:00, 57.59it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0580, -0.0038,  0.0102],\n",
      "        [-0.0821, -0.0235,  0.0370]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 9:  67%|   | 2/3 [00:00<00:00, 58.55it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0652,  0.0132,  0.0151]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 9: 100%|| 3/3 [00:00<00:00, 60.00it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0639,  0.0043,  0.0186],\n",
      "        [-0.0698,  0.0108,  0.0113]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0853, -0.0194,  0.0389],\n",
      "        [-0.0579, -0.0064,  0.0113]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0530,  0.0171,  0.0224]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]       IN MODEL DEF SEN\n",
      "tensor([[-0.0530, -0.0055,  0.0098],\n",
      "        [-0.0859, -0.0186,  0.0449]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 10:  33%|      | 1/3 [00:00<00:00, 72.92it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0562,  0.0123,  0.0229],\n",
      "        [-0.0665,  0.0026,  0.0192]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 10:  67%|   | 2/3 [00:00<00:00, 71.70it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0676,  0.0068,  0.0098]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 10: 100%|| 3/3 [00:00<00:00, 74.26it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0625,  0.0038,  0.0177],\n",
      "        [-0.0701,  0.0120,  0.0100]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0859, -0.0200,  0.0399],\n",
      "        [-0.0568, -0.0064,  0.0102]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0533,  0.0182,  0.0216]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0605, -0.0127,  0.0066],\n",
      "        [-0.0643,  0.0055,  0.0181]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 11:  33%|      | 1/3 [00:00<00:00, 72.48it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0834, -0.0120,  0.0443],\n",
      "        [-0.0677,  0.0129,  0.0090]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 11:  67%|   | 2/3 [00:00<00:00, 74.64it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0546,  0.0197,  0.0241]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 11: 100%|| 3/3 [00:00<00:00, 72.62it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0612,  0.0033,  0.0168],\n",
      "        [-0.0704,  0.0134,  0.0086]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0863, -0.0204,  0.0407],\n",
      "        [-0.0557, -0.0063,  0.0091]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0536,  0.0193,  0.0208]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0729,  0.0152,  0.0086],\n",
      "        [-0.0933, -0.0191,  0.0424]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 12:  33%|      | 1/3 [00:00<00:00, 67.92it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0681,  0.0032,  0.0088],\n",
      "        [-0.0522,  0.0187,  0.0247]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 12:  67%|   | 2/3 [00:00<00:00, 73.04it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0577, -0.0019,  0.0035]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 12: 100%|| 3/3 [00:00<00:00, 73.68it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0600,  0.0029,  0.0160],\n",
      "        [-0.0707,  0.0148,  0.0073]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0869, -0.0208,  0.0416],\n",
      "        [-0.0548, -0.0060,  0.0080]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0541,  0.0206,  0.0199]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0469,  0.0208,  0.0188],\n",
      "        [-0.0718,  0.0208,  0.0086]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 13:  33%|      | 1/3 [00:00<00:00, 60.85it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0519, -0.0039,  0.0098],\n",
      "        [-0.0821, -0.0196,  0.0453]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 13:  67%|   | 2/3 [00:00<00:00, 67.67it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0558,  0.0045,  0.0159]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 13: 100%|| 3/3 [00:00<00:00, 67.19it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0589,  0.0025,  0.0151],\n",
      "        [-0.0710,  0.0161,  0.0060]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0873, -0.0212,  0.0424],\n",
      "        [-0.0536, -0.0060,  0.0068]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0546,  0.0219,  0.0189]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0475,  0.0235,  0.0239],\n",
      "        [-0.0544,  0.0022,  0.0174]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 14:  33%|      | 1/3 [00:00<00:00, 71.95it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0514, -0.0089,  0.0046],\n",
      "        [-0.0921, -0.0170,  0.0478]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 14:  67%|   | 2/3 [00:00<00:00, 73.11it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0645,  0.0175,  0.0050]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 14: 100%|| 3/3 [00:00<00:00, 71.14it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0574,  0.0020,  0.0142],\n",
      "        [-0.0711,  0.0171,  0.0049]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0877, -0.0218,  0.0432],\n",
      "        [-0.0525, -0.0060,  0.0056]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0550,  0.0231,  0.0181]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0549, -0.0059,  0.0128],\n",
      "        [-0.0939, -0.0155,  0.0421]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 15:  33%|      | 1/3 [00:00<00:00, 53.05it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0527, -0.0073,  0.0030],\n",
      "        [-0.0717,  0.0161,  0.0078]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 15:  67%|   | 2/3 [00:00<00:00, 53.48it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0574,  0.0284,  0.0166]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 15: 100%|| 3/3 [00:00<00:00, 54.23it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0561,  0.0015,  0.0132],\n",
      "        [-0.0714,  0.0182,  0.0037]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0881, -0.0223,  0.0441],\n",
      "        [-0.0514, -0.0059,  0.0045]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0553,  0.0242,  0.0173]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0477,  0.0014,  0.0002],\n",
      "        [-0.0693,  0.0201,  0.0034]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 16:  33%|      | 1/3 [00:00<00:00, 65.36it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0613, -0.0047,  0.0145],\n",
      "        [-0.0848, -0.0207,  0.0427]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 16:  67%|   | 2/3 [00:00<00:00, 61.43it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0551,  0.0244,  0.0179]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 16: 100%|| 3/3 [00:00<00:00, 67.16it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0550,  0.0011,  0.0124],\n",
      "        [-0.0717,  0.0195,  0.0025]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0886, -0.0228,  0.0449],\n",
      "        [-0.0503, -0.0058,  0.0033]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0558,  0.0255,  0.0164]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0837, -0.0135,  0.0461],\n",
      "        [-0.0511,  0.0216,  0.0141]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 17:  33%|      | 1/3 [00:00<00:00, 76.50it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0585, -0.0024,  0.0101],\n",
      "        [-0.0486, -0.0096,  0.0082]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 17:  67%|   | 2/3 [00:00<00:00, 73.89it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0719,  0.0199, -0.0018]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 17: 100%|| 3/3 [00:00<00:00, 76.74it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0538,  0.0008,  0.0115],\n",
      "        [-0.0719,  0.0206,  0.0014]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0891, -0.0232,  0.0459],\n",
      "        [-0.0493, -0.0056,  0.0023]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0564,  0.0272,  0.0154]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0522, -0.0057, -0.0046],\n",
      "        [-0.0750,  0.0194,  0.0002]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 18:  33%|      | 1/3 [00:00<00:00, 70.40it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0901, -0.0166,  0.0417],\n",
      "        [-0.0597,  0.0315,  0.0202]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 18:  67%|   | 2/3 [00:00<00:00, 67.27it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0557, -0.0104,  0.0070]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 18: 100%|| 3/3 [00:00<00:00, 68.31it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0527,  0.0004,  0.0106],\n",
      "        [-0.0723,  0.0220,  0.0002]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0897, -0.0237,  0.0467],\n",
      "        [-0.0483, -0.0054,  0.0011]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0569,  0.0287,  0.0146]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s, v_num=10]        IN MODEL DEF SEN\n",
      "tensor([[-0.0421,  0.0036,  0.0031],\n",
      "        [-0.0795,  0.0201, -0.0006]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 19:  33%|      | 1/3 [00:00<00:00, 70.32it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0538, -0.0048,  0.0094],\n",
      "        [-0.0902, -0.0200,  0.0507]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 19:  67%|   | 2/3 [00:00<00:00, 69.77it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0614,  0.0272,  0.0133]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "SEN\n",
      "Epoch 19: 100%|| 3/3 [00:00<00:00, 71.86it/s, v_num=10]IN MODEL DEF SEN\n",
      "tensor([[-0.0513, -0.0001,  0.0097],\n",
      "        [-0.0725,  0.0231, -0.0009]], device='cuda:0', dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-9.0088e-02, -2.4109e-02,  4.7485e-02],\n",
      "        [-4.7241e-02, -5.2948e-03,  1.5259e-05]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "IN MODEL DEF SEN\n",
      "tensor([[-0.0573,  0.0299,  0.0137]], device='cuda:0', dtype=torch.float16)\n",
      "Epoch 19: 100%|| 3/3 [00:00<00:00, 32.91it/s, v_num=10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|| 3/3 [00:00<00:00,  7.91it/s, v_num=10]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(multi_model, datamodule=sentiment_dm)\n",
    "trainer.test(multi_model, datamodule=sentiment_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627fc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "class NERDataModule(LightningDataModule):\n",
    "    def __init__(self, ner_data, ner_ignore_idx, batch_size):\n",
    "        super().__init__()\n",
    "        self.ner_data = ner_data\n",
    "        self.ner_ignore_idx = ner_ignore_idx\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = NERDatasetClass(self.ner_data, self.ner_ignore_idx)\n",
    "        self.val_dataset = NERDatasetClass(self.ner_data, self.ner_ignore_idx)\n",
    "        self.test_dataset = NERDatasetClass(self.ner_data, self.ner_ignore_idx)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33046d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dm = NERDataModule(ner_data=ner_data, ner_ignore_idx=-100, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444cdb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type               | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | backbone                | BertModel          | 22.7 M | eval \n",
      "1 | sentiment_analysis_head | Sequential         | 74.5 K | train\n",
      "2 | named_entity_rec_head   | Sequential         | 75.7 K | train\n",
      "3 | sent_crit               | CrossEntropyLoss   | 0      | train\n",
      "4 | ner_crit                | CrossEntropyLoss   | 0      | train\n",
      "5 | sentiment_acc           | MulticlassAccuracy | 0      | train\n",
      "6 | ner_f1                  | MulticlassF1Score  | 0      | train\n",
      "-----------------------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "22.7 M    Non-trainable params\n",
      "22.9 M    Total params\n",
      "91.453    Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "120       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saira\\miniforge3\\envs\\fetcch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saira\\miniforge3\\envs\\fetcch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\saira\\miniforge3\\envs\\fetcch\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s] NER\n",
      "Epoch 0:  33%|      | 1/3 [00:00<00:00, 15.46it/s, v_num=12]NER\n",
      "Epoch 0:  67%|   | 2/3 [00:00<00:00, 26.41it/s, v_num=12]NER\n",
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 1:  33%|      | 1/3 [00:00<00:00, 73.94it/s, v_num=12]NER\n",
      "Epoch 1:  67%|   | 2/3 [00:00<00:00, 78.30it/s, v_num=12]NER\n",
      "Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 2:  33%|      | 1/3 [00:00<00:00, 73.95it/s, v_num=12]NER\n",
      "Epoch 2:  67%|   | 2/3 [00:00<00:00, 65.48it/s, v_num=12]NER\n",
      "Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 3:  33%|      | 1/3 [00:00<00:00, 69.28it/s, v_num=12]NER\n",
      "Epoch 3:  67%|   | 2/3 [00:00<00:00, 75.61it/s, v_num=12]NER\n",
      "Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 4:  33%|      | 1/3 [00:00<00:00, 64.41it/s, v_num=12]NER\n",
      "Epoch 4:  67%|   | 2/3 [00:00<00:00, 68.75it/s, v_num=12]NER\n",
      "Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 5:  33%|      | 1/3 [00:00<00:00, 73.50it/s, v_num=12]NER\n",
      "Epoch 5:  67%|   | 2/3 [00:00<00:00, 78.25it/s, v_num=12]NER\n",
      "Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 6:  33%|      | 1/3 [00:00<00:00, 61.83it/s, v_num=12]NER\n",
      "Epoch 6:  67%|   | 2/3 [00:00<00:00, 67.30it/s, v_num=12]NER\n",
      "Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 7:  33%|      | 1/3 [00:00<00:00, 77.15it/s, v_num=12]NER\n",
      "Epoch 7:  67%|   | 2/3 [00:00<00:00, 72.31it/s, v_num=12]NER\n",
      "Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 8:  33%|      | 1/3 [00:00<00:00, 66.78it/s, v_num=12]NER\n",
      "Epoch 8:  67%|   | 2/3 [00:00<00:00, 71.47it/s, v_num=12]NER\n",
      "Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 9:  33%|      | 1/3 [00:00<00:00, 74.70it/s, v_num=12]NER\n",
      "Epoch 9:  67%|   | 2/3 [00:00<00:00, 76.60it/s, v_num=12]NER\n",
      "Epoch 10:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]       NER\n",
      "Epoch 10:  33%|      | 1/3 [00:00<00:00, 74.70it/s, v_num=12]NER\n",
      "Epoch 10:  67%|   | 2/3 [00:00<00:00, 70.66it/s, v_num=12]NER\n",
      "Epoch 11:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 11:  33%|      | 1/3 [00:00<00:00, 71.87it/s, v_num=12]NER\n",
      "Epoch 11:  67%|   | 2/3 [00:00<00:00, 75.67it/s, v_num=12]NER\n",
      "Epoch 12:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 12:  33%|      | 1/3 [00:00<00:00, 69.04it/s, v_num=12]NER\n",
      "Epoch 12:  67%|   | 2/3 [00:00<00:00, 74.54it/s, v_num=12]NER\n",
      "Epoch 13:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 13:  33%|      | 1/3 [00:00<00:00, 70.23it/s, v_num=12]NER\n",
      "Epoch 13:  67%|   | 2/3 [00:00<00:00, 76.27it/s, v_num=12]NER\n",
      "Epoch 14:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 14:  33%|      | 1/3 [00:00<00:00, 85.59it/s, v_num=12]NER\n",
      "Epoch 14:  67%|   | 2/3 [00:00<00:00, 81.56it/s, v_num=12]NER\n",
      "Epoch 15:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 15:  33%|      | 1/3 [00:00<00:00, 63.75it/s, v_num=12]NER\n",
      "Epoch 15:  67%|   | 2/3 [00:00<00:00, 63.99it/s, v_num=12]NER\n",
      "Epoch 16:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 16:  33%|      | 1/3 [00:00<00:00, 75.04it/s, v_num=12]NER\n",
      "Epoch 16:  67%|   | 2/3 [00:00<00:00, 59.07it/s, v_num=12]NER\n",
      "Epoch 17:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 17:  33%|      | 1/3 [00:00<00:00, 83.29it/s, v_num=12]NER\n",
      "Epoch 17:  67%|   | 2/3 [00:00<00:00, 59.76it/s, v_num=12]NER\n",
      "Epoch 18:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 18:  33%|      | 1/3 [00:00<00:00, 57.16it/s, v_num=12]NER\n",
      "Epoch 18:  67%|   | 2/3 [00:00<00:00, 58.42it/s, v_num=12]NER\n",
      "Epoch 19:   0%|          | 0/3 [00:00<?, ?it/s, v_num=12]        NER\n",
      "Epoch 19:  33%|      | 1/3 [00:00<00:00, 59.62it/s, v_num=12]NER\n",
      "Epoch 19:  67%|   | 2/3 [00:00<00:00, 59.38it/s, v_num=12]NER\n",
      "Epoch 19: 100%|| 3/3 [00:00<00:00, 29.30it/s, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|| 3/3 [00:00<00:00,  7.24it/s, v_num=12]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(multi_model, datamodule=ner_dm)\n",
    "trainer.test(multi_model, datamodule=ner_dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fetcch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
